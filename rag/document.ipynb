{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b48d1009",
   "metadata": {},
   "source": [
    "### Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40d747b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Document structure\n",
    "from langchain_core.documents import Document\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82e3e0f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'example.txt', 'pages': 10, 'author': 'John Doe', 'date_created': '2026-01-15'}, page_content='This is the content of the document.')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc=Document(page_content=\"This is the content of the document.\", \n",
    "metadata={\n",
    "    \"source\": \"example.txt\",\n",
    "    \"pages\": 10,\n",
    "    \"author\": \"John Doe\",\n",
    "    \"date_created\": \"2026-01-15\"\n",
    "    }\n",
    ")\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d5882ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File found at: e:\\Programming\\ML\\jupyter-notebooks\\notebook\\text_files/test_document.txt\n",
      "File size: 333 bytes\n",
      "\n",
      "--- Document Object ---\n",
      "Page Content:\n",
      "This is a sample document for testing the Document class.\n",
      "It contains multiple lines of text.\n",
      "The Document class from langchain_core can process this content.\n",
      "We can also store metadata about this document such as source, author, and creation date.\n",
      "This file is created to demonstrate basic file operations using the os module.\n",
      "\n",
      "\n",
      "Metadata: {'source': 'e:\\\\Programming\\\\ML\\\\jupyter-notebooks\\\\notebook\\\\text_files/test_document.txt', 'file_name': 'test_document.txt', 'directory': 'e:\\\\Programming\\\\ML\\\\jupyter-notebooks\\\\notebook\\\\text_files', 'file_size': 333}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the file path\n",
    "file_path = os.path.join(os.getcwd(), \"text_files/test_document.txt\")\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(file_path):\n",
    "    print(f\"File found at: {file_path}\")\n",
    "    print(f\"File size: {os.path.getsize(file_path)} bytes\")\n",
    "    \n",
    "    # Read the file content\n",
    "    with open(file_path, 'r') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # Create a Document object with the file content\n",
    "    doc = Document(\n",
    "        page_content=content,\n",
    "        metadata={\n",
    "            \"source\": file_path,\n",
    "            \"file_name\": os.path.basename(file_path),\n",
    "            \"directory\": os.path.dirname(file_path),\n",
    "            \"file_size\": os.path.getsize(file_path)\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    print(\"\\n--- Document Object ---\")\n",
    "    print(f\"Page Content:\\n{doc.page_content}\")\n",
    "    print(f\"\\nMetadata: {doc.metadata}\")\n",
    "else:\n",
    "    print(f\"File not found at: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d88f79e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': './text_files/test_document.txt'}, page_content='This is a sample document for testing the Document class.\\nIt contains multiple lines of text.\\nThe Document class from langchain_core can process this content.\\nWe can also store metadata about this document such as source, author, and creation date.\\nThis file is created to demonstrate basic file operations using the os module.\\n')]\n"
     ]
    }
   ],
   "source": [
    "### TextLoaders\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader=TextLoader(\"./text_files/test_document.txt\", encoding=\"utf-8\")\n",
    "document=loader.load()\n",
    "print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8039353f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'text_files\\\\data_science.txt'}, page_content='Data Science and Analytics\\n\\nData science is an interdisciplinary field that uses scientific methods, processes, algorithms and systems to extract meaningful information from data.\\n\\nKey Components of Data Science:\\n1. Data Collection - Gathering data from various sources\\n2. Data Cleaning - Preparing and validating data quality\\n3. Exploratory Data Analysis - Understanding data patterns and relationships\\n4. Statistical Analysis - Applying statistical methods to draw conclusions\\n5. Machine Learning Modeling - Building predictive models\\n6. Data Visualization - Presenting insights through visual representations\\n\\nTools and Technologies:\\n- Python with libraries like pandas, scikit-learn, and matplotlib\\n- R for statistical computing\\n- SQL for database queries\\n- Spark for big data processing\\n- Tableau and Power BI for visualization\\n\\nCareer Path:\\nData scientists combine programming skills, statistical knowledge, and domain expertise to solve real-world problems. They work across various industries including finance, healthcare, e-commerce, and technology.\\n\\nThe demand for data science professionals continues to grow as organizations increasingly rely on data-driven decision making to gain competitive advantages.\\n'),\n",
       " Document(metadata={'source': 'text_files\\\\test_document.txt'}, page_content='This is a sample document for testing the Document class.\\nIt contains multiple lines of text.\\nThe Document class from langchain_core can process this content.\\nWe can also store metadata about this document such as source, author, and creation date.\\nThis file is created to demonstrate basic file operations using the os module.\\n')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Directory Loader\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "##load all the text files from the directory\n",
    "dir_loader=DirectoryLoader(\n",
    "    \"./text_files\",\n",
    "    glob=\"**/*.txt\",\n",
    "    loader_cls= TextLoader,\n",
    "    loader_kwargs={\"encoding\":\"utf-8\"},\n",
    "    show_progress=False\n",
    ")\n",
    "\n",
    "documents=dir_loader.load()\n",
    "documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b5e9c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'ReportLab PDF Library - (opensource)', 'creator': 'anonymous', 'creationdate': '2026-01-30T17:23:53+05:00', 'source': 'pdf_files\\\\document1.pdf', 'file_path': 'pdf_files\\\\document1.pdf', 'total_pages': 1, 'format': 'PDF 1.3', 'title': 'untitled', 'author': 'anonymous', 'subject': 'unspecified', 'keywords': '', 'moddate': '2026-01-30T17:23:53+05:00', 'trapped': '', 'modDate': \"D:20260130172353+05'00'\", 'creationDate': \"D:20260130172353+05'00'\", 'page': 0}, page_content='Machine Learning Fundamentals\\nThis is the first dummy PDF document.\\nIt contains information about machine learning basics.\\nMachine learning algorithms learn patterns from data.\\nCommon types: Supervised, Unsupervised, Reinforcement Learning.\\nApplications include image recognition, NLP, and recommendations.\\nDeep learning uses neural networks for complex tasks.'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - (opensource)', 'creator': 'anonymous', 'creationdate': '2026-01-30T17:23:53+05:00', 'source': 'pdf_files\\\\document2.pdf', 'file_path': 'pdf_files\\\\document2.pdf', 'total_pages': 1, 'format': 'PDF 1.3', 'title': 'untitled', 'author': 'anonymous', 'subject': 'unspecified', 'keywords': '', 'moddate': '2026-01-30T17:23:53+05:00', 'trapped': '', 'modDate': \"D:20260130172353+05'00'\", 'creationDate': \"D:20260130172353+05'00'\", 'page': 0}, page_content='Advanced Data Science Techniques\\nThis is the second dummy PDF document.\\nIt covers advanced topics in data science.\\nFeature engineering improves model performance.\\nCross-validation prevents overfitting.\\nHyperparameter tuning optimizes model accuracy.\\nEnsemble methods combine multiple models.')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader, PyMuPDFLoader\n",
    "\n",
    "##load all the text files from the directory\n",
    "dir_loader=DirectoryLoader(\n",
    "    \"./pdf_files\",\n",
    "    glob=\"**/*.pdf\",\n",
    "    loader_cls= PyMuPDFLoader,\n",
    "    show_progress=False\n",
    ")\n",
    "\n",
    "pdf_documents=dir_loader.load()\n",
    "pdf_documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57587114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.documents.base.Document"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pdf_documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350b1f58",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
